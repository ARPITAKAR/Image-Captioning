ğŸ“˜ Image Captioning Application â€” DenseNet201 + LSTM + Streamlit + Docker + AWS EC2

An end-to-end Image Captioning System that generates natural-language captions for uploaded images using DenseNet201 as a feature extractor and an LSTM decoder.
The entire application is containerized with Docker and deployed on AWS EC2.

ğŸ“Œ Table of Contents

Overview

Model Architecture

Training Pipeline

Inference Flow

Streamlit Frontend

Project Structure

Setup Instructions

Run Locally

Docker Build & Run

AWS EC2 Deployment

Issues & Solutions

Links

ğŸ” Overview

This project implements a computer vision + NLP pipeline that can look at an image and generate a meaningful caption. It combines:

DenseNet201 (pretrained on ImageNet) â†’ extracts visual features

LSTM decoder â†’ generates captions token-by-token

Streamlit UI â†’ user uploads an image and sees generated captions

Docker â†’ packaging for reproducibility

AWS EC2 â†’ cloud deployment

ğŸ§  Model Architecture
1ï¸âƒ£ DenseNet201 Feature Extractor

Loaded DenseNet201 without its classification head

Extracted feature vector from the Global Average Pooling layer

Output embedding size: 1920

2ï¸âƒ£ Caption Decoder (LSTM)

Tokenized captions using Keras Tokenizer

Generated sequences using teacher forcing

Combined:

Image embedding (Dense â†’ Reshape)

Embedded caption tokens

LSTM(256)

Added skip-connection from image embedding to LSTM output

Final prediction layer: Dense(vocab_size, softmax)

3ï¸âƒ£ Loss / Training

Categorical cross-entropy

Optimized using Adam

Custom data generator using tf.keras.utils.Sequence

âš™ï¸ Training Pipeline
Custom Data Generator (Sequence)

Handles:

batching

tokenization

padding

generating (input sequence â†’ next word) pairs

combining image features + partial captions

Ensures memory efficiency during training.

ğŸš€ Inference Flow

Load:

model.keras

feature_extractor.keras

tokenizer.pkl

Preprocess uploaded image:

Resize â†’ 224Ã—224

Normalize

Extract 1920-dim feature vector

Start caption with "startseq"

Iterate until:

"endseq" is predicted

or max length reached

Render caption in Streamlit UI.

ğŸ¨ Streamlit Frontend

Upload an image (JPG/PNG)

Model generates caption in real time

Display image + caption

Uses Matplotlib for visualization

Clean, minimal UI

Run locally:

streamlit run densenets.py

ğŸ“ Project Structure
ğŸ“¦ image-captioning
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ model.keras
â”‚   â”œâ”€â”€ feature_extractor.keras
â”‚   â””â”€â”€ tokenizer.pkl
â”œâ”€â”€ densenets.py        # Streamlit app file
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â””â”€â”€ utils/              # (optional helpers)

ğŸ› ï¸ Setup Instructions
Clone this repository
git clone <your-repo-url>
cd image-captioning

Install dependencies
pip install -r requirements.txt

Run Streamlit App
streamlit run densenets.py

ğŸ³ Docker Build & Run
Build Image
docker build -t arpit1004/tiger .

Run Container
docker run -p 8000:8000 arpit1004/tiger

Open application:
http://localhost:8000

â˜ï¸ AWS EC2 Deployment
1ï¸âƒ£ Launch EC2 Instance

OS: Ubuntu

Type: t3.small (recommended for TensorFlow)

Allow ports:

22 (SSH)

8000 (app)

2ï¸âƒ£ Install Docker
sudo apt update
sudo apt install -y docker.io
sudo systemctl start docker
sudo usermod -aG docker $USER
exit


Re-login.

3ï¸âƒ£ Pull Image
docker pull arpit1004/tiger

4ï¸âƒ£ Run Container
docker run -p 8000:8000 arpit1004/tiger

5ï¸âƒ£ Access App
http://<PUBLIC_IP>:8000
